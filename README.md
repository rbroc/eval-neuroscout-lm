### Evaluating LLMs on forward language modeling for NeuroScout transcripts
To dos
[] Make list of models to expand to
    Forward language models:
    - GPT-Neo / GPT-J
    - BlenderBot
    Bidirectional language models
    - Bigbird
    - BERT / DistilBERT
    - RoBERTa - RobertaForCausalLM
    - BART for conditional generation

Potential classes:
    - CausalLM
    - Conditional generation
    - MaskedLM
[] Implement code for each of the models
[] Clean up code
[] Add more qualitative discussion to the paper 
[] Add references on syntax / downstream tasks 
[] Try out downstream tasks?
